{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iar_project.utils as utils\n",
    "import iar_project.features_extraction as extraction\n",
    "import iar_project.test_clustering as clustering\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many images ?\n",
    "nb_im = 12 #to which image\n",
    "k = 0 # from which image\n",
    "seg_img=utils.import_seg_results(k,nb_im)\n",
    "sol_img=utils.import_solution()\n",
    "sol_img=[sol_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n",
    "features=extraction.get_features_color(seg_img)\n",
    "img_5=seg_img[5]\n",
    "img_5_gray=[cv2.cvtColor(im, cv2.COLOR_RGB2GRAY) for im in img_5]\n",
    "img_5_entropy=[entropy(gray_im, disk(2)) for gray_im in img_5_gray ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "GENERAL_PATH = (\n",
    "    \"/Users/begue/OneDrive/Documents/EPFL/Master/Cours/MA2/IAPR/projet/iar_project\"\n",
    ")\n",
    "DATA_PATH = GENERAL_PATH + \"/data_project\"\n",
    "DATA_PATH2 = GENERAL_PATH + \"/data_project2\"\n",
    "SEGMENTATION_OUTPUT_PATH = DATA_PATH + \"/segmentation_results\"\n",
    "SEGMENTATION_OUTPUT_PATH2 = DATA_PATH2 + \"/segmentation_results\"\n",
    "SOL_OUTPUT_PATH2 = DATA_PATH2 + \"/train2_solutions\"\n",
    "CLUSTERING_OUTPUT_PATH2 = DATA_PATH2 + \"/clustering_results\"\n",
    "img_list = []\n",
    "\n",
    "seg_path = SEGMENTATION_OUTPUT_PATH2 + \"/\" + \"*.png\"\n",
    "tmp = []\n",
    "for filename in glob.glob(seg_path):\n",
    "    if os.path.exists(filename):\n",
    "        img = cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_list.append(img[10:118,10:118,:])\n",
    "    else:\n",
    "        print(f\"Image {filename} not found.\")\n",
    "        print(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray=[cv2.cvtColor(im, cv2.COLOR_RGB2GRAY) for im in img_list]\n",
    "img_entropy=[entropy(gray_im, disk(2)) for gray_im in img_gray ]\n",
    "img_s=[cv2.cvtColor(im, cv2.COLOR_RGB2HSV)[:,:,0] for im in img_list]\n",
    "img_g=[im[:,:,1] for im in img_list]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=extraction.get_features_color([img_list])\n",
    "features = features[0]\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ft = np.mean(features, axis=0)\n",
    "std_ft = np.std(features, axis=0)\n",
    "ft_norm = (features - mean_ft) / std_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 25\n",
    "kmeans = KMeans(n_clusters=K, n_init=50, init=\"random\").fit(ft_norm[:,0:6])\n",
    "labels = kmeans.labels_\n",
    "unique_lab = np.unique(labels)\n",
    "# nb_tiles = []\n",
    "clu = []\n",
    "for l, lab in enumerate(unique_lab):\n",
    "    # print(lab)\n",
    "    idx = np.argwhere(labels == lab)\n",
    "    puzzle = []\n",
    "    for i, id in enumerate(idx):\n",
    "        # print(id[0])\n",
    "        puzzle.append(img_list[id[0]])\n",
    "    clu.append(puzzle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,8))\n",
    "for c,cluster in enumerate(clu):\n",
    "    for t,tile in enumerate(cluster):\n",
    "        ab = AnnotationBbox(OffsetImage(tile, zoom=.1), (t+1,c+1),frameon=False)\n",
    "        ax.add_artist(ab)\n",
    "    \n",
    "plt.xticks(range(50))\n",
    "plt.yticks(range(K+2))\n",
    "#plt.ylim([0,4])\n",
    "#plt.xlim([0,28])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,8))\n",
    "for i in range(len(img_entropy)):\n",
    "    ab = AnnotationBbox(OffsetImage(img_list[i], zoom=.1), (np.mean(img_g[i].ravel()), np.median(img_entropy[i].ravel())),frameon=False)\n",
    "    ax.add_artist(ab)\n",
    "    \n",
    "plt.xticks(range(len(img_entropy)))\n",
    "plt.yticks(range(len(img_entropy)))\n",
    "plt.ylim([0,4])\n",
    "plt.xlim([0,255])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image 5\n",
    "Good separation using mean or std+mean of the entropiy with radius of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "for i in range(len(img_5)):\n",
    "    plt.subplot(3,10,i+1)\n",
    "    plt.imshow(img_5[i])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "for i in range(len(img_5_entropy)):\n",
    "    plt.subplot(3,10,i+1)\n",
    "    plt.hist(img_5_entropy[i].ravel())\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(len(img_5_entropy)):\n",
    "    ab = AnnotationBbox(OffsetImage(img_5[i], zoom=.1), (i, np.median(img_5_entropy[i].ravel())),frameon=False)\n",
    "    ax.add_artist(ab)\n",
    "    \n",
    "plt.xticks(range(len(img_5_entropy)))\n",
    "plt.yticks(range(len(img_5_entropy)))\n",
    "plt.ylim([0,4])\n",
    "plt.xlim([0,28])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "img_5=seg_img[5]\n",
    "img_5_gray=[cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)[10:118,10:118] for im in img_5]\n",
    "img_5_h=[np.fft.rfft2(im) for im in img_5_gray]\n",
    "img_5_entropy=[entropy(gray_im, disk(2)) for gray_im in img_5_gray ]\n",
    "\n",
    "img_5_c=[cv2.cvtColor(im, cv2.COLOR_RGB2HSV)[10:118,10:118,1] for im in img_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(len(img_5_entropy)):\n",
    "    ax.scatter(np.std(img_5_c[i].ravel()), np.median(img_5_entropy[i].ravel()))\n",
    "    ab = AnnotationBbox(OffsetImage(img_5[i], zoom=.1), (np.std(img_5_c[i].ravel()), np.median(img_5_entropy[i].ravel())),frameon=False)\n",
    "    ax.add_artist(ab)\n",
    "    \n",
    "#plt.xticks(range(len(img_5_entropy)))\n",
    "#plt.yticks(range(len(img_5_entropy)))\n",
    "#plt.ylim([0,4])\n",
    "#plt.xlim([0,2])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image 6\n",
    "\n",
    "Good separation using mean +std of saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_6=seg_img[6]\n",
    "img_6_gray=[cv2.cvtColor(im, cv2.COLOR_RGB2HSV)[10:118, 10:118,1] for im in img_6]\n",
    "img_6_h=[im[10:118, 10:118,0] for im in img_6]\n",
    "img_6_entropy=[entropy(gray_im, disk(1)) for gray_im in img_6_gray ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "for i in range(len(img_6)):\n",
    "    plt.subplot(3,10,i+1)\n",
    "    plt.imshow(img_6_gray[i])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,5))\n",
    "for i in range(len(img_6_entropy)):\n",
    "    plt.subplot(3,10,i+1)\n",
    "    plt.hist(img_6_gray[i].ravel())\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for i in range(len(img_6_gray)):\n",
    "    ax.scatter(i, np.mean(img_6_gray[i].ravel()))\n",
    "    ab = AnnotationBbox(OffsetImage(img_6[i], zoom=.1), (i, np.mean(img_6_gray[i].ravel())),frameon=False)\n",
    "    ax.add_artist(ab)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for i in range(len(img_6_gray)):\n",
    "    ax.scatter(np.std(img_6_h[i].ravel()), np.mean(img_6_gray[i].ravel()))\n",
    "    ab = AnnotationBbox(OffsetImage(img_6[i], zoom=.1), (np.std(img_6_h[i].ravel()), np.mean(img_6_gray[i].ravel())),frameon=False)\n",
    "    ax.add_artist(ab)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iar_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
